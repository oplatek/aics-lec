\documentclass{beamer}
\usetheme{Warsaw}
\useinnertheme{circles}
\useoutertheme[subsection=false]{smoothbars}
\usepackage[utf8x]{inputenc}
\usepackage[czech]{babel}
\usepackage[T1]{fontenc}
\usepackage{listings}
\usepackage{tikz}
\lstset{basicstyle=\tiny\ttfamily}
\logo{\includegraphics[height=0.5cm]{brmlab.pdf}}

\begin{document}

\AtBeginSection[]
{
  \begin{frame}
    \frametitle{Outline}
    \tableofcontents[currentsection]
  \end{frame}
}

\title{brmiversity: Umělá inteligence \\ a teoretická informatika}
\subtitle{Přednáška č. 10}
\author{Petr Baudiš $\langle${\tt pasky@ucw.cz}$\rangle$}
\institute{
	brmlab 2011\\
	\vskip 1ex
	\pgfdeclareimage[height=4ex]{ccbysa}{by-sa.pdf}
	\pgfuseimage{ccbysa}
}
\date{}
\frame{\titlepage}

\section{Umělá inteligence a adaptivní agenti}

\subsection{}
\begin{frame}{Strojové učení}
\begin{center}
Učící se agent: Datový vstup a výstup, rozhodovací problém, užitková funkce
\vskip 3ex
\begin{block}{Máme trénovací množinu}
\begin{itemize}
\item Učení s učitelem vs. bez učitele
\item Rozpoznávání vs. samoorganizace
\end{itemize}
\end{block}
\begin{block}{Nemáme trénovací množinu (i když\dots)}
\begin{itemize}
\item Exploration---exploitation dilemma
\item Zpětnovazebné učení
\end{itemize}
\end{block}
\end{center}
\end{frame}

\subsection{}
\begin{frame}{Zpětnovazebné učení}
\begin{center}
Dnes: Nemáme klasickou trénovací množinu, \\
ale {\bf feedback} --- učitelem je prostředí. \\
Data si často musíme shánět ``sami'' průběžně. \\
Jinak řečeno: Agentův {\bf stav} se mění a provádí {\bf akce}.

\vskip 6ex

{\bf Reinforcement learning} je ztělesněním jádra UI. \\
	Agenta umístíme do prostředí, sám se musí naučit \\ svoji ``přechodovou funkci''.
\end{center}
\end{frame}

\subsection{}
\begin{frame}{Zpětnovazebné učení}
\begin{itemize}
\item Strategie agenta (policy) $\pi\colon S \to A$ \\ $\pi(s)=a$ zvolí ve stavu $s$ akci $a$
\item Na základě akcí dostáváme {\bf zpětnou vazbu} \\ Někdy hned, ale často až za dlouho! \\ Jak to modelovat?
\item {\bf Pasivní učení:} Během učení používáme fixní $\pi$
\item {\bf Aktivní učení:} Strategii $\pi$ průběžně měníme
\end{itemize}
\end{frame}

\subsection{}
\begin{frame}{Bellmannova rovnice}
\begin{itemize}
\item Každý stav má {\bf ocenění} $R$ (reward)
\item K zajímavému stavu se můžeme dostat různými cestami
\item {\bf Užitek} je celkové ``hodnocení výkonu'' agenta, \\ distribuované přes posloupnost stavů
\item $U[s_0,s_1,s_2,\ldots] = R(s_0) + \gamma(R(s_1) + \gamma(R(s_2) + \cdots)) \quad \gamma \in [0,1]$
\pause
\vskip 2ex
\item Akce nemusí vždy dopadnout stejně --- pravděpodobnostní rozdělení; Markovský rozhodovací proces (MDP)!
\item $\pi(s) = \mathrm{argmax}_{a \in A(s)} \sum_{s'} P(s'|s,a) U(s')$ \\ (vyber akci s nejvyšším {\em očekávaným} užitkem)
\pause
\vskip 2ex
\item Volí-li agent optimální akci, užitek stavu závisí na užitku okolních stavů
\item {\bf Bellmanova rovnice:} $U(s) = R(s) + \gamma \max_{a \in A(s)} \sum_{S'} P(s'|s,a) U(s')$
\end{itemize}
\end{frame}

\subsection{}
\begin{frame}{Pasivní učení}
\begin{itemize}
\item Agent neprozkoumává prostředí, vzorkuje s pevnou $\pi$
\item Chceme {\em ohodnotit} $\pi$, tzn. zjistit očekávaný $U^\pi$
\item Neznáme $P(s'|s,a)$ ani $R(s)$, potřebujeme zjistit $U$
\end{itemize}
\vskip 3ex
\begin{block}{Přímý model}
\begin{itemize}
\item Naivní: Užitek stavu buď průměrné ocenění cesty do cíle
\item Ignorujeme interakce mezi stavy a ostří $\pi$ (Bellmanova rovnice)
\item Funguje, ale konverguje pomalu!
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Adaptivní dynamické programování}
\begin{itemize}
\item ADP: Ze vzorků získáme $R$, postupně dopočítáváme $P$ a $U$
\item $P$ na základě empirických četností
\item $U$ {\bf iterativním vzorkováním} pomocí Bellmanovy rovnice (Monte Carlo metoda; TODO)
\item Funguje, ale časově náročné kroky a hodně paměti
\end{itemize}
\end{frame}

\begin{frame}{Temporální diference}
\begin{itemize}
\item TD-learning: Počítáme přímo $U$ podle ``skoku užitku''
\item $U$ inicializuji podle $R$; ve stavu $s$ dostanu reinforcement $R$, vykonám akci $a$ a ocitnu se ve stavu $s'$
\item TD(0) pravidlo: $U(s) \leftarrow U(s) + \alpha(R(s) + \gamma U(s') - U(s))$
\item $\alpha \in (0,1)$ je parametr učení; díváme se o stav {\em dopředu} a~provádíme {\em backup}
\item Méně paměti, mnoho krátkých kroků, neudržuje konzistenci
\end{itemize}
\begin{block}{Jak to funguje?}
\begin{itemize}
\item $U[s_0,s_1,s_2,\ldots] = R(s_0) + \gamma(R(s_1) + \gamma(R(s_2) + \cdots))$ \\
	$U[s_0,s_1,s_2,\ldots] = R(s_0) + \gamma U[s_1,s_2,\ldots]$
\item Posouváme se k $U(s_0) = \mathbb{E}[R(s_0) + \gamma U(s_1)]$
\end{itemize}
\end{block}
\end{frame}

\subsection{}
\begin{frame}{Aktivní učení}
\begin{center}
{\bf Aktivní učení:} Adaptivní strategie. \\
Měli bychom při učení již co nejlépe fungovat. \\
Učit se chceme co nejefektivněji. \\
Problém výběru akcí --- zase!

\pause
\vskip 3ex

{\bf Hladový agent} se i průběžně drží $\pi(s) = \mathrm{argmax}_{a \in A(s)} \sum_{s'} P(s'|s,a) U(s')$ \\
Je něco lepšího?

\pause
\vskip 3ex

Exploration: Data o alternativách. \\
Exploitation: Výběr nejlepší alternativy. \\
Exploration a exploitation nemohou být v opozici natrvalo.
\end{center}
\end{frame}

\begin{frame}{Exploration-exploitation dilemma}
\begin{itemize}
\item Problém mnohorukého loupežníka (multi-armed bandit) (TODO obrázek)
\item Robot v bludišti
\item Hraní šachů nebo Go
\item Genetický algoritmus
\end{itemize}
\vskip 3ex
\begin{block}{Strategie řešení}
\begin{itemize}
\item {\bf Semi-uniformní:} $\varepsilon$-greedy
\item {\bf Oceňovací:} $U^+ \leftarrow R(s) + \gamma \max_a f(U^+(a), N(s,a))$ \\
	$f(u,n)$ klesá v $u$, roste v $n$ --- třeba prahová \\
	$u=U^+$ zajišťuje preferenci neprozkoumaných oblastí \\
	Alternativa: upper confidence bounds
\item Optimální strategie vybere nejlepší akci exponenciálně častěji než jakoukoliv jinou
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Aktivní TD agent}
\begin{block}{Druhy aktivních agentů}
\begin{itemize}
\item {\bf Utility based agent} se učí užitek pro stavy (nutný model)
\item {\bf Q-learning based agent} se učí očekávaný užitek pro akce
\item {\bf Reflex based agent} se učí přímo $\pi(s)$
\end{itemize}
\end{block}
\begin{itemize}
\item Naivně: Přechodový model ADP agenta (učíme se $P(s'|s,a)$, apriorní znalost), update funkce užitku jako TD(0)
\item Q-učení: Bezmodelový --- učíme se hodnotu akce $Q(s,a)$ \\
	Místo $U(s)$ se TD(0) aplikuje na $Q(s,a)$ \\
	\only<1>{$U(s) \leftarrow U(s) + \alpha(R(s) + \gamma U(s') - U(s))$} \pause
	$Q(s,a) \leftarrow Q(s,a) + \alpha(R(s) + \gamma \max_{a'} Q(s',a') - Q(s,a))$
\pause
\item SARSA: State-Action-Reward-State-Action \\
	Při update čekáme na další akci \\
	$Q(s,a) \leftarrow Q(s,a) + \alpha(R(s) + \gamma Q(s',a') - Q(s,a))$
\item Jaký je rozdíl pro hladového agenta? \pause Žádný!
\item A při průzkumu? \pause SARSA zesiluje efekt strategie \pause (dvojsečné)
\end{itemize}
\end{frame}

\subsection{}
\begin{frame}{Zpětnovazebné učení v neuronových sítích}
\begin{columns}
\begin{column}{4cm}
\includegraphics[width=4cm]{nornbrain.png}

{\tiny (Brom, 2006)}
\end{column}
\begin{column}{8cm}
\begin{itemize}
\item Mozek umělé bytosti ``Norn''
\item Perception: egg, toy, Norn, hunger, sexdrive
\item Concept: egg + hunger, Norn + sexdrive, \\ toy + egg + sexdrive
\item Decision: eat, mate, run, play
\only<1>{
\item Pomocný okruh pro Attention selection
\item Chceme podporovat užitečné koncepty a~vázat je na dobré akce
\item Náhodně inicializované váhy a~zpětná vazba!
\item Reinforcement záleží na změně {\em pudů} \\ (drives: hlad, sex, \dots)
}
\only<2>{
\item Suspectibility $\alpha$ a~průběžný reinforcement $r$
\item Vykonání akce zvýší $\alpha$ spojům po cestě, \\ to se s časem opět snižuje
\item Po snížení váhy k nule synapse migruje
\item Robustnost: Short-term weight, \\ long-term weight
}
\end{itemize}
\end{column}
\end{columns}
\end{frame}

\subsection{}
\begin{frame}{Otázky?}
\begin{center}
Příště UI: Reprezentace znalostí.

Příště Adaptivní agenti: Etologie a populační dynamika.
\end{center}
\end{frame}

\section{Datové struktury}

\subsection{}
\begin{frame}{Halda}
\begin{itemize}
\item Chceme ukládat data tak, abychom \\ vždy mohli snadno vytáhnout minimum
\vskip 3ex
\item Speciálně uspořádaný strom: synové jsou vždy větší než otec
\item Tedy v kořeni je nejmenší prvek
\item Chceme podporovat zejména operace INSERT, DELETEMIN
\item Může se hodit i INCREASE a DECREASE
\end{itemize}
\begin{tikzpicture}[remember picture,overlay]
  \node [xshift=-4.5cm,yshift=-4.5cm,above right] at (current page.north east)
    {\includegraphics[width=4cm]{Heap.pdf}};
\end{tikzpicture}
\end{frame}

\subsection{}
\begin{frame}{Regulární halda}
\begin{itemize}
\item Pěkně ``zarovnaný'' strom, každý otec \\ kromě těch u dna má dva syny \\ (má hloubku $\log n$)
\item Mezi syny není žádné pořadí
\item INSERT: Přidáme na ``konec'' haldy \\ (na dně), posouváme nahoru, dokud je porušena podmínka
\item DELETEMIN: Prohodíme kořen a poslední prvek, umažeme poslední prvek, prvek z kořene posouváme dolů
\item Složitosti $O(\log n)$
\item Heap sort!
\end{itemize}
\begin{tikzpicture}[remember picture,overlay]
  \node [xshift=-4.5cm,yshift=-5cm,above right] at (current page.north east)
    {\includegraphics[width=4cm]{Heap.pdf}};
\end{tikzpicture}
\end{frame}

\subsection{}
\begin{frame}{Levicové (leftist) haldy}
\begin{itemize}
\item Místo probublávání bude základní operace MERGE dvou hald
\item INSERT: MERGE s jednoprvkovou haldou
\item DELETEMIN: MERGE synů kořene
\vskip 3ex
\item Línější strukturální podmínka: {\em levý syn má vždy delší cestu k~nejbližšímu listu}
\item Překvapení: délka pravé cesty je nejvýše logaritmická!
\item Záruka efektivity: MERGE půjde po pravé cestě
\vskip 3ex
\item $MERGE(A,B)$ nastaví $RIGHT(A)=B$ a opraví haldu (haldová a cestová podmínka)
\item Pokud již $RIGHT(A)$ předtím existovalo, pustíme pak $MERGE(RIGHT(A), OLDRIGHT(A))$
\item DECREASE a INCREASE: Utrhneme podstrom, \\ rekurzivně opravíme rodiče a MERGE
\end{itemize}
\end{frame}

\subsection{}
\begin{frame}{Binomiální stromy}
\begin{center}
\includegraphics[width=8cm]{Binomial_Trees.pdf}
\end{center}
\begin{itemize}
\item Binomiální strom: $H_0$ je jeden uzel, $H_{i+1} = \oplus(H_i, H'_i)$ kde $H'_i$ přidáme jako dalšího syna kořene $H_i$
\end{itemize}
\end{frame}

\subsection{}
\begin{frame}{Binomiální haldy}
\begin{itemize}
\item Binomiální halda: Binomiální les \\ s haldovou podmínkou, maximálně \\ jeden strom každé velikosti
\item $MERGE(A,B)$ funguje jako sčítání dvou binárních čísel! Existuje-li $H_i$ jen v jedné, zkopíruje se; \\ jinak vyrobím přenos $H^T_{i+1} =\oplus(H^A_i, H^B_i)$
\item MIN je relativně pomalé $O(\log N)$ --- musí projít celý les
\item Liná binomiální halda: MERGE neslučuje, zato MIN ano; amortizovaně MIN stále $O(\log N)$
\end{itemize}
\begin{tikzpicture}[remember picture,overlay]
  \node [xshift=-5cm,yshift=-4cm,above right] at (current page.north east)
    {\includegraphics[width=4.5cm]{Binomial_Trees.pdf}};
\end{tikzpicture}
\end{frame}

\subsection{}
\begin{frame}{Fibonacciho haldy}
\begin{itemize}
\item Zobecnění líné binomiální haldy --- chceme zrychlit INCREASE a DECREASE
\item Zrušíme strukturální podmínku na $H_i$ \\ $i$ bude popisovat pouze {\em rank}, totiž počet synů kořenu \\ (uvnitř synů to může vypadat, jakkoliv nám dovolí algoritmus)
\item Vrchol je {\em obarvený}, byl-li mu někdy utrhnut syn
\vskip 2ex
\item MERGE a MIN jako u líné binomální haldy
\item DECREASE a INCREASE: Utrhneme podstrom, rekurzivně opravíme rodiče a MERGE (jako v leftist haldě!)
\item Oprava rodičů: Označené také utrhneme
\item MIN je stále amortizovaně $O(\log N)$ (dokážeme, že maximální počet synů každého uzlu je nejvýše $\log N$, dá se ukázat přes Fibonacciho posloupnost)
\end{itemize}
\end{frame}

\subsection{}
\begin{frame}{B-stromy}
\begin{center}
\includegraphics[width=8cm]{B-tree.pdf}
\end{center}
\begin{itemize}
\item Vyhledávací strom s jednou hodnotou v uzlu: \\ nevhodný pro pomalý přímý přístup (I/O, cache)
\item B-strom: Mnoho definic, nejobecnější je $(a,b)$ strom
\vskip 3ex
\item $(a,b)$ strom ($a \le b$): každý vnitřní vrchol kromě kořene má alespoň $a$ a nejvíce $b$ synů a všechny cesty od kořene k listu mají stejnou délku
\item V praxi navíc: $a \ge 2$, $b \ge 2b-1$; kořen je buď list, \\ nebo má alespoň 2 a nejvíce $b$ synů
\end{itemize}
\vskip 1ex
\end{frame}

\subsection{}
\begin{frame}{B-stromy}
\begin{itemize}
\item Populární: 2-3 strom, v praxi \\ ovšem často spíše 128-256 \\ strom apod. (v závislosti na velikosti bloku)
\item Díky $b \ge 2b-1$ mohu vždy sloučit dva $a$-prázdné uzly nebo rozštěpit jeden plný
\item Vyvažování v INSERT a DELETE: Propaguji chybu vzhůru --- snažím se vyměňovat prvky se sourozenci, v extrémním případě rozštěpím kořen
\vskip 3ex
\item A-sort: Třídění pomocí přidávání do B-stromu, INSERT začíná v listu (výhodné pro částečně předtříděné posloupnosti)
\end{itemize}
\begin{tikzpicture}[remember picture,overlay]
  \node [xshift=-5.5cm,yshift=-3.2cm,above right] at (current page.north east)
    {\includegraphics[width=5cm]{B-tree.pdf}};
\end{tikzpicture}
\end{frame}

\subsection{}
\begin{frame}{Otázky?}
\begin{center}
Příště: Datové struktury v externí paměti.
\end{center}
\end{frame}

\subsection{}
\begin{frame}{Děkuji vám}
\begin{center}
{\bf pasky@ucw.cz}

\vskip 6ex

Příště: Neuronové sítě.
	Adaptivní agenti.
	Evoluční algoritmy (koevoluce, otevřená evoluce, teoretická analýza). \\
	Složitost (vlastnosti tříd složitosti).
\end{center}
\end{frame}

\end{document}
